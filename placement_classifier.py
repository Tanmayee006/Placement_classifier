# -*- coding: utf-8 -*-
"""Placement_classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V6vSVaRCeJ0rPYnLvMnzz7E_fH3t8DMb
"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

train_df = pd.read_csv('train.csv')

placement = train_df['Placement']

X = train_df.drop(["Name", "Placement"], axis=1)

X.fillna(X.mean(), inplace=True)

# Logistic regression
clf_lr = LogisticRegression(random_state=42)
clf_lr.fit(X, placement)

# SVM classifier
clf_svm = SVC(kernel='linear', random_state=50)
clf_svm.fit(X, placement)

# Random Forest classifier
clf_rf = RandomForestClassifier(n_estimators=1000, random_state=42)
clf_rf.fit(X, placement)

# XGBoost classifier
clf_xgb = XGBClassifier(n_estimators=1000, learning_rate=0.05, random_state=42)
clf_xgb.fit(X, placement)

test_df = pd.read_csv("test.csv")

student_ids = test_df["Studid"]

X_test = test_df.drop(["Studid", "Name"], axis=1)
X_test.fillna(X_test.mean(), inplace=True)
X_test.rename(columns={"10th %": "10th %age", "12%": "12th %age", 'College%': 'College %age', "Amcat": "Automata(Score_5154)"}, inplace=True)

y_preds_lr = clf_lr.predict(X_test)
y_preds_svm = clf_svm.predict(X_test)
y_preds_rf = clf_rf.predict(X_test)
y_preds_xgb = clf_xgb.predict(X_test)

y_test = pd.read_csv("Sample_submission.csv")["Placement"]
accuracy_lr = accuracy_score(y_test, y_preds_lr)
accuracy_svm = accuracy_score(y_test, y_preds_svm)
accuracy_rf = accuracy_score(y_test, y_preds_rf)
accuracy_xgb = accuracy_score(y_test, y_preds_xgb)

print(f"Model Accuracy on Test Set using Logistic regression: {accuracy_lr * 100:.2f}%")
print(f"Model Accuracy on Test Set using SVM: {accuracy_svm * 100:.2f}%")
print(f"Model Accuracy on Test Set using RandomForestClassifier: {accuracy_rf * 100:.2f}%")
print(f"Model Accuracy on Test Set using XGBoost: {accuracy_xgb * 100:.2f}%")

prediction_lr = pd.DataFrame({'Studid': student_ids, 'TARGET': y_preds_lr})
prediction_svm = pd.DataFrame({'Studid': student_ids, 'TARGET': y_preds_svm})
prediction_rf = pd.DataFrame({'Studid': student_ids, 'TARGET': y_preds_rf})
prediction_xgb = pd.DataFrame({'Studid': student_ids, 'TARGET': y_preds_xgb})

prediction_lr.to_csv('Prediction_result_lr.csv', index=False)
# prediction_svm.to_csv('Prediction_result_svm.csv', index=False)
# prediction_rf.to_csv('Prediction_result_rf.csv', index=False)
# prediction_xgb.to_csv('Prediction_result_xgb.csv', index=False)

print(prediction_lr.head())
print(prediction_svm.head())
print(prediction_rf.tail())
print(prediction_xgb.tail())

models = ['LogisticRegression','SVM', 'RandomForest', 'XGBoost']
accuracies = [accuracy_lr , accuracy_svm, accuracy_rf, accuracy_xgb]

plt.bar(models, accuracies, color=['orange','blue', 'green', 'red'])
plt.xlabel('Models')
plt.ylabel('Accuracy')
plt.title('Model Accuracies on Test Set')
plt.ylim(0, 1)  # Assuming accuracy is between 0 and 1
plt.show()

